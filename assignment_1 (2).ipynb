{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cbe8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1: data1.csv\n",
      "Iterations 0, Loss: 0.6921578814351956\n",
      "Iterations 100, Loss: 0.6036875220827\n",
      "Iterations 200, Loss: 0.5328792593561658\n",
      "Iterations 300, Loss: 0.4757958298479238\n",
      "Iterations 400, Loss: 0.4293254288542837\n",
      "Iterations 500, Loss: 0.39108166475527806\n",
      "Iterations 600, Loss: 0.35925860670069737\n",
      "Iterations 700, Loss: 0.33249344569447037\n",
      "Iterations 800, Loss: 0.30975420466501935\n",
      "Iterations 900, Loss: 0.2902538888858622\n",
      "Optimal Parameters for file 1:\n",
      "[-0.00167865  0.62533039]\n",
      "0.2902538888858622\n",
      "accuracy 99.4\n",
      "Processing file 2: data12.csv\n",
      "Iterations 0, Loss: 0.6566374516953546\n",
      "Iterations 100, Loss: 0.45326291531055024\n",
      "Iterations 200, Loss: 0.43167547786865235\n",
      "Iterations 300, Loss: 0.4211472314078763\n",
      "Iterations 400, Loss: 0.41469246778214774\n",
      "Iterations 500, Loss: 0.4102466396022887\n",
      "Iterations 600, Loss: 0.4069559235034316\n",
      "Iterations 700, Loss: 0.4044018176202778\n",
      "Iterations 800, Loss: 0.4023538994011773\n",
      "Iterations 900, Loss: 0.40067351132005397\n",
      "Optimal Parameters for file 2:\n",
      "[-4.23320799e-03 -1.46718463e-02 -2.59287926e-02  1.69443862e-02\n",
      "  1.56859500e-02 -2.53574409e-02  1.65280461e-03  3.00100906e-02\n",
      "  2.27598968e-02 -2.78708799e-02 -5.62695219e-04  2.26501377e-02\n",
      "  1.19135994e-04  1.27860168e-02  4.23341293e-02 -3.36307222e-02\n",
      " -1.23978550e-01 -8.20457720e-04  4.34018311e-03  4.03055736e-02\n",
      " -3.70270967e-02 -5.15627061e-02  1.34981925e-02 -8.88870457e-02\n",
      "  6.41628389e-02  2.04456469e-02 -9.64825263e-03 -3.62425371e-02\n",
      "  1.06648160e-02 -2.05962143e-02 -4.42991593e-02 -3.60470639e-03\n",
      "  9.72366020e-02  8.87165520e-03  6.98414452e-02  6.09968416e-02\n",
      "  6.60976901e-03 -3.25728858e-02  3.83242123e-04 -6.41335733e-02\n",
      " -3.75143470e-02  5.37671181e-02 -2.04381461e-02 -8.38334853e-03\n",
      "  2.62010169e-02 -1.08942136e-02 -1.55112891e-04 -3.77175700e-02\n",
      " -1.40653926e-02  1.76542966e-02  1.23180306e-02]\n",
      "0.40067351132005397\n",
      "accuracy 82.19999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit  # sigmoid function\n",
    "\n",
    "# List of file names\n",
    "files = ['data1.csv', 'data12.csv']\n",
    "\n",
    "# Loop through each file\n",
    "for i, files in enumerate(files, start = 1):\n",
    "    print(f\"Processing file {i}: {files}\")\n",
    "    \n",
    "    df = pd.read_csv(files)  # Replace 'your_file.csv' with the actual file path\n",
    "    info = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    # X refers to features  y target values\n",
    "    X = info.iloc[:, :-1].values\n",
    "    y = info.iloc[:, -1].values\n",
    "\n",
    "    # Add a column of ones to the features for the bias term\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Initialize parameters\n",
    "    coefficient = np.zeros(X.shape[1])\n",
    "    lr = 0.001\n",
    "    lambda_parameter = 0.01\n",
    "    num_of_iterations = 1000\n",
    "\n",
    "    # Logistic sigmoid function\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # Regularized log loss function\n",
    "    def log_loss(coefficient, X, y, lambda_parameter):\n",
    "        m = len(y)\n",
    "        h = sigmoid(np.dot(X, coefficient))\n",
    "        h = np.clip(h, 1e-15, 1 - 1e-15)\n",
    "        loss = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) / m\n",
    "        reg_term = (lambda_parameter) * np.sum(coefficient[1:]**2)  # Exclude bias term\n",
    "        return loss + reg_term\n",
    "\n",
    "    # Gradient of regularized log loss function\n",
    "    def gradient_ridge(coefficient, X, y, lambda_parameter):\n",
    "        m = len(y)\n",
    "        h = sigmoid(np.dot(X, coefficient)) # h= prediction, errors = h-y\n",
    "        h = np.clip(h, 1e-15, 1 - 1e-15)\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        reg_term = 2 * (lambda_parameter) * np.r_[0, coefficient[1:]]  # Include 0 for bias term\n",
    "        return gradient + reg_term \n",
    "\n",
    "    # Gradient descent for regularized log loss\n",
    "    def gradient_descent(X, y, coefficient, lr, lambda_parameter, num_of_iterations):\n",
    "        for itr in range(num_of_iterations):\n",
    "            gradient = gradient_ridge(coefficient, X, y, lambda_parameter)\n",
    "            coefficient -= lr * gradient\n",
    "            if itr % 100 == 0:\n",
    "                loss = log_loss(coefficient, X, y, lambda_parameter)\n",
    "                print(f\"Iterations {itr}, Loss: {loss}\")\n",
    "        return coefficient, loss\n",
    "    \n",
    "    def accuracy(X, coefficient):\n",
    "        prob = sigmoid( np.dot(X, coefficient))\n",
    "        return (prob >= 0.5).astype(int)\n",
    "\n",
    "    # Apply gradient descent\n",
    "    optimal_coefficient, loss = gradient_descent(X, y, coefficient, lr, lambda_parameter, num_of_iterations)\n",
    "    \n",
    "\n",
    "    # Display the optimal parameters\n",
    "    print(f\"Optimal Parameters for file {i}:\")\n",
    "    print(optimal_coefficient)\n",
    "    print(loss)\n",
    "    predict = accuracy(X, optimal_coefficient )\n",
    "    accur = np.mean(predict == y) * 100\n",
    "    print(\"accuracy\", accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e3c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
